{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-23T01:06:21.267393608Z",
     "start_time": "2024-01-23T01:06:20.778846629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LimeAnalyser._load_data(): Loading file ../data/12872/0/12872_idx5_x2401_y651_class0.png\n",
      "LimeAnalyser._load_data(): Loading file ../data/10254/0/10254_idx5_x1551_y1251_class0.png\n",
      "LimeAnalyser._load_data(): Loading file ../data/10303/1/10303_idx5_x951_y1351_class1.png\n",
      "LimeAnalyser._load_data(): Loading file ../data/15472/1/15472_idx5_x1451_y1501_class1.png\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import lime\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "from skimage.color import label2rgb\n",
    "from lime import lime_image\n",
    "from PIL import ImageFilter, ImageEnhance, Image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "class LimeAnalyser:\n",
    "    def __init__(self):\n",
    "        self._data = pd.read_csv('all_outputs.csv')\n",
    "        self._tagged_data_path = '/home/mdrzewiecki/mim/BreastCancerAnalysis/data/'\n",
    "        self._choose_tagged_sample()\n",
    "        self._setup_sample_files()\n",
    "        self._setup_explainer()\n",
    "        self._positive_label = \"Cancer\"\n",
    "        self._negative_label = \"Healthy\"\n",
    "        \n",
    "    @property\n",
    "    def x(self):\n",
    "        return self._x\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._y\n",
    "    \n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "    \n",
    "    @property\n",
    "    def segmenter(self):\n",
    "        return self._segmenter\n",
    "    \n",
    "    def _predict_fn(self, sample_batch):\n",
    "        print(f\"predfn, sample shape={sample_batch.shape}\")\n",
    "        #for i in range(len(sample_batch[0])):\n",
    "        #    sample = Image.fromarray(sample)\n",
    "        #    sample = tf.convert_to_tensor(sample)\n",
    "        #    sample = sample[None, :, :, :]\n",
    "        self._model.predict(sample_batch)\n",
    "    \n",
    "    def explain_tagged_files(self, num_samples):\n",
    "        selected_ids = np.random.randint(0, 1000, num_samples)\n",
    "        _, sample_file_name = os.path.split(self._chosen_image_path)\n",
    "        image = Image.open(self._chosen_image_path)\n",
    "        ground_truth = Image.open(self._chosen_image_ground_truth)\n",
    "        for i in selected_ids:\n",
    "            print(f\"file: {sample_file_name}, sample: {i}\")\n",
    "            \n",
    "            image_part = image.crop((i, i, i + 50, i + 50))\n",
    "            ground_truth_part = ground_truth.crop((i, i, i + 50, i + 50))\n",
    "            ground_truth_part = ground_truth_part.resize((360, 360))\n",
    "            ground_truth_image = (np.array(ground_truth_part))\n",
    "            image_part = np.asarray(image_part)\n",
    "            \n",
    "            print(image_part.shape)\n",
    "            \n",
    "            explanation = self._explainer.explain_instance(\n",
    "                image_part, self._predict_fn, top_labels=5, num_samples=500, segmentation_fn=analyzer.segmenter, hide_color=0)\n",
    "            temp_without_background, mask_without_background = explanation.get_image_and_mask(\n",
    "                label=0, positive_only=True, num_features=5, hide_rest=True)\n",
    "            temp_with_background, mask_with_background = explanation.get_image_and_mask(\n",
    "                label=0, positive_only=False, num_features=5, hide_rest=False)\n",
    "            \n",
    "            img_without_background = mark_boundaries(temp_without_background / 2 + 0.5, mask_without_background)\n",
    "            img_with_background = mark_boundaries(temp_with_background / 2 + 0.5, mask_with_background)\n",
    "            \n",
    "            \n",
    "            #display(Image.fromarray(img_without_background[0]))\n",
    "            #display(Image.fromarray(img_with_background[0]))\n",
    "            display(Image.fromarray(ground_truth_image))\n",
    "            \n",
    "            plt.imshow(temp_without_background[0])\n",
    "            plt.show()\n",
    "            plt.imshow(mask_without_background[0])\n",
    "            plt.show()\n",
    "            \n",
    "            #display(result_img)\n",
    "            \n",
    "            print(\"========================================================\")\n",
    "    \n",
    "    def explain_sample_files(self, num_samples=500):\n",
    "        explanation = explainer.explain_instance(\n",
    "            analyzer.x[0], \n",
    "            classifier_fn=analyzer.model.predict,\n",
    "            top_labels=2,\n",
    "            hide_color=0, \n",
    "            num_samples=num_samples, \n",
    "            segmentation_fn=analyzer.segmenter)\n",
    "        temp, mask = explanation.get_image_and_mask(analyzer.y[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2, figsize = (8, 4))\n",
    "        ax1.imshow(mask,temp, interpolation = 'nearest')\n",
    "        ax1.set_title('Positive Regions for {}'.format(analyzer.y[0]))\n",
    "        temp, mask = explanation.get_image_and_mask(y[0], positive_only=False, num_features=10, hide_rest=False)\n",
    "        ax2.imshow(label2rgb(3-mask,temp, bg_label = 0), interpolation = 'nearest')\n",
    "        ax2.set_title('Positive/Negative Regions for {}'.format(analyzer.y[0]))\n",
    "    \n",
    "    def _choose_tagged_sample(self):\n",
    "        self._data_original_images_dir = os.path.join(self._tagged_data_path, 'images')\n",
    "        self._data_ground_truth_dir = os.path.join(self._tagged_data_path, 'groundTruth_display')\n",
    "        cases = next(os.walk(self._data_original_images_dir))[2]\n",
    "        chosen_tagged_image = cases[random.randint(0, len(cases))]\n",
    "        chosen_tagged_ground_truth = os.path.splitext(chosen_tagged_image)[0]+'.png'\n",
    "        self._chosen_image_path = os.path.join(self._data_original_images_dir, chosen_tagged_image)\n",
    "        self._chosen_image_ground_truth = os.path.join(self._data_ground_truth_dir, chosen_tagged_ground_truth)\n",
    "    \n",
    "    def _setup_sample_files(self):\n",
    "        self._false_predictions = self._data.loc[(self._data[\"pred_y\"] > 0.5) != self._data[\"true_y\"]]\n",
    "        self._false_positives = self._false_predictions.loc[self._false_predictions[\"pred_y\"] > 0.5]\n",
    "        self._false_negatives = self._false_predictions.loc[self._false_predictions[\"pred_y\"] < 0.5]\n",
    "        self._false_positive_files = self._false_positives['# file']\n",
    "        self._false_negative_files = self._false_negatives['# file']\n",
    "        self._false_negatives_sample = np.random.randint(0, len(self._false_negative_files), 2)\n",
    "        self._false_positives_sample = np.random.randint(0, len(self._false_positive_files), 2)\n",
    "        self._false_negative_sample_files = self._false_negative_files.iloc[self._false_negatives_sample]\n",
    "        self._false_positive_sample_files = self._false_positive_files.iloc[self._false_positives_sample]\n",
    "        self._sample_files = self._false_positive_sample_files._append(self._false_negative_sample_files)\n",
    "        self._load_data(sample_files, end=4)\n",
    "    \n",
    "    def _load_data(self, files, start=0, end=10, augment_fn=None):\n",
    "        X = []\n",
    "        y = []\n",
    "        for f in files[start:end]:\n",
    "            print(f'LimeAnalyser._load_data(): Loading file {f}')\n",
    "            img = load_img(f, target_size=(50, 50))\n",
    "            if augment_fn is not None:\n",
    "                sample = augment_fn(img)\n",
    "            else:    \n",
    "                sample = tf.convert_to_tensor(img)\n",
    "            X.append(sample)\n",
    "            y.append(f[-5])\n",
    "        self._x = np.stack(X)\n",
    "        self._y = np.array(y, dtype=float)\n",
    "    \n",
    "    def _setup_explainer(self):\n",
    "        self._model = keras.models.load_model(\"../models/CanDetect.keras\")\n",
    "        self._explainer = lime_image.LimeImageExplainer(verbose=False)\n",
    "        self._segmenter = SegmentationAlgorithm('slic', n_segments=100, compactness=1, sigma=1)\n",
    "\n",
    "analyzer = LimeAnalyser()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: Case_10-04.tif, sample: 106\n",
      "(50, 50, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db71be7e6a864665a059e2bc6864b70f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predfn, sample shape=(10, 50, 50, 3)\n",
      "1/1 [==============================] - 0s 137ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[142], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43manalyzer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain_tagged_files\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[141], line 73\u001B[0m, in \u001B[0;36mLimeAnalyser.explain_tagged_files\u001B[0;34m(self, num_samples)\u001B[0m\n\u001B[1;32m     69\u001B[0m image_part \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(image_part)\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28mprint\u001B[39m(image_part\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 73\u001B[0m explanation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_explainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain_instance\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m    \u001B[49m\u001B[43mimage_part\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_labels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m500\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msegmentation_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43manalyzer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msegmenter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhide_color\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m temp_without_background, mask_without_background \u001B[38;5;241m=\u001B[39m explanation\u001B[38;5;241m.\u001B[39mget_image_and_mask(\n\u001B[1;32m     76\u001B[0m     label\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, positive_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_features\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, hide_rest\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     77\u001B[0m temp_with_background, mask_with_background \u001B[38;5;241m=\u001B[39m explanation\u001B[38;5;241m.\u001B[39mget_image_and_mask(\n\u001B[1;32m     78\u001B[0m     label\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, positive_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, num_features\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, hide_rest\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/mim/BreastCancerAnalysis/venv/lib/python3.10/site-packages/lime/lime_image.py:198\u001B[0m, in \u001B[0;36mLimeImageExplainer.explain_instance\u001B[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001B[0m\n\u001B[1;32m    194\u001B[0m     fudged_image[:] \u001B[38;5;241m=\u001B[39m hide_color\n\u001B[1;32m    196\u001B[0m top \u001B[38;5;241m=\u001B[39m labels\n\u001B[0;32m--> 198\u001B[0m data, labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfudged_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msegments\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m                                \u001B[49m\u001B[43mclassifier_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    200\u001B[0m \u001B[43m                                \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    202\u001B[0m distances \u001B[38;5;241m=\u001B[39m sklearn\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mpairwise_distances(\n\u001B[1;32m    203\u001B[0m     data,\n\u001B[1;32m    204\u001B[0m     data[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m),\n\u001B[1;32m    205\u001B[0m     metric\u001B[38;5;241m=\u001B[39mdistance_metric\n\u001B[1;32m    206\u001B[0m )\u001B[38;5;241m.\u001B[39mravel()\n\u001B[1;32m    208\u001B[0m ret_exp \u001B[38;5;241m=\u001B[39m ImageExplanation(image, segments)\n",
      "File \u001B[0;32m~/mim/BreastCancerAnalysis/venv/lib/python3.10/site-packages/lime/lime_image.py:262\u001B[0m, in \u001B[0;36mLimeImageExplainer.data_labels\u001B[0;34m(self, image, fudged_image, segments, classifier_fn, num_samples, batch_size)\u001B[0m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(imgs) \u001B[38;5;241m==\u001B[39m batch_size:\n\u001B[1;32m    261\u001B[0m         preds \u001B[38;5;241m=\u001B[39m classifier_fn(np\u001B[38;5;241m.\u001B[39marray(imgs))\n\u001B[0;32m--> 262\u001B[0m         \u001B[43mlabels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    263\u001B[0m         imgs \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(imgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[0;31mTypeError\u001B[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "analyzer.explain_tagged_files(3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T01:06:21.586641544Z",
     "start_time": "2024-01-23T01:06:21.270984574Z"
    }
   },
   "id": "71fe4917819156b7",
   "execution_count": 142
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
