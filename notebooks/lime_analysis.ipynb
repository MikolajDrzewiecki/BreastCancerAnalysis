{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-23T01:49:44.205874693Z",
     "start_time": "2024-01-23T01:49:43.800218696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LimeAnalyser._load_data(): Loading file ../data/12872/0/12872_idx5_x2401_y651_class0.png\n",
      "LimeAnalyser._load_data(): Loading file ../data/10254/0/10254_idx5_x1551_y1251_class0.png\n",
      "LimeAnalyser._load_data(): Loading file ../data/10303/1/10303_idx5_x951_y1351_class1.png\n",
      "LimeAnalyser._load_data(): Loading file ../data/15472/1/15472_idx5_x1451_y1501_class1.png\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import lime\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "from skimage.color import label2rgb\n",
    "from lime import lime_image\n",
    "from PIL import ImageFilter, ImageEnhance, Image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "class LimeAnalyser:\n",
    "    def __init__(self):\n",
    "        self._data = pd.read_csv('all_outputs.csv')\n",
    "        self._tagged_data_path = '/home/mdrzewiecki/mim/BreastCancerAnalysis/data/'\n",
    "        self._choose_tagged_sample()\n",
    "        self._setup_sample_files()\n",
    "        self._setup_explainer()\n",
    "        self._positive_label = \"Cancer\"\n",
    "        self._negative_label = \"Healthy\"\n",
    "        \n",
    "    @property\n",
    "    def x(self):\n",
    "        return self._x\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._y\n",
    "    \n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "    \n",
    "    @property\n",
    "    def segmenter(self):\n",
    "        return self._segmenter\n",
    "    \n",
    "    def pred_fn(self, sample):\n",
    "        return self._model.predict(sample)\n",
    "    \n",
    "    def explain_tagged_files(self, num_samples):\n",
    "        selected_ids = np.random.randint(0, 1000, num_samples)\n",
    "        _, sample_file_name = os.path.split(self._chosen_image_path)\n",
    "        image = Image.open(self._chosen_image_path)\n",
    "        ground_truth = Image.open(self._chosen_image_ground_truth)\n",
    "        for i in selected_ids:\n",
    "            print(f\"file: {sample_file_name}, sample: {i}\")\n",
    "            \n",
    "            image_part = image.crop((i, i, i + 50, i + 50))\n",
    "            ground_truth_part = ground_truth.crop((i, i, i + 50, i + 50))\n",
    "            ground_truth_part = ground_truth_part.resize((360, 360))\n",
    "            ground_truth_image = (np.array(ground_truth_part))\n",
    "            image_part = np.array(image_part)\n",
    "            \n",
    "            explanation = self._explainer.explain_instance(\n",
    "                image_part, self.pred_fn, top_labels=5, num_samples=500, segmentation_fn=analyzer.segmenter, hide_color=0)\n",
    "            temp_without_background, mask_without_background = explanation.get_image_and_mask(\n",
    "                explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "            temp_with_background, mask_with_background = explanation.get_image_and_mask(\n",
    "                explanation.top_labels[0], positive_only=False, num_features=5, hide_rest=False)\n",
    "            \n",
    "            img_without_background = mark_boundaries(temp_without_background / 2 + 0.5, mask_without_background.astype(\"int8\"))\n",
    "            img_with_background = mark_boundaries(temp_with_background / 2 + 0.5, mask_with_background)\n",
    "                        \n",
    "                        \n",
    "            return Image.fromarray(temp_without_background.astype(np.uint8))\n",
    "            #display(Image.fromarray(img_without_background[0]))\n",
    "            #display(Image.fromarray(img_with_background[0]))\n",
    "            display(Image.fromarray(ground_truth_image))\n",
    "            print(temp_without_background)\n",
    "            print(mask_without_background)\n",
    "            \n",
    "            #plt.imshow(temp_without_background)\n",
    "            #plt.show()\n",
    "            #plt.imshow(mask_without_background)\n",
    "            #plt.show()\n",
    "            \n",
    "            #display(result_img)\n",
    "            \n",
    "            print(\"========================================================\")\n",
    "            \n",
    "    \n",
    "    def explain_sample_files(self, num_samples=500):\n",
    "        explanation = explainer.explain_instance(\n",
    "            analyzer.x[0], \n",
    "            classifier_fn=analyzer.model.predict,\n",
    "            top_labels=2,\n",
    "            hide_color=0, \n",
    "            num_samples=num_samples, \n",
    "            segmentation_fn=analyzer.segmenter)\n",
    "        temp, mask = explanation.get_image_and_mask(analyzer.y[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2, figsize = (8, 4))\n",
    "        ax1.imshow(mask,temp, interpolation = 'nearest')\n",
    "        ax1.set_title('Positive Regions for {}'.format(analyzer.y[0]))\n",
    "        temp, mask = explanation.get_image_and_mask(y[0], positive_only=False, num_features=10, hide_rest=False)\n",
    "        ax2.imshow(label2rgb(3-mask,temp, bg_label = 0), interpolation = 'nearest')\n",
    "        ax2.set_title('Positive/Negative Regions for {}'.format(analyzer.y[0]))\n",
    "    \n",
    "    def _choose_tagged_sample(self):\n",
    "        self._data_original_images_dir = os.path.join(self._tagged_data_path, 'images')\n",
    "        self._data_ground_truth_dir = os.path.join(self._tagged_data_path, 'groundTruth_display')\n",
    "        cases = next(os.walk(self._data_original_images_dir))[2]\n",
    "        chosen_tagged_image = cases[random.randint(0, len(cases))]\n",
    "        chosen_tagged_ground_truth = os.path.splitext(chosen_tagged_image)[0]+'.png'\n",
    "        self._chosen_image_path = os.path.join(self._data_original_images_dir, chosen_tagged_image)\n",
    "        self._chosen_image_ground_truth = os.path.join(self._data_ground_truth_dir, chosen_tagged_ground_truth)\n",
    "    \n",
    "    def _setup_sample_files(self):\n",
    "        self._false_predictions = self._data.loc[(self._data[\"pred_y\"] > 0.5) != self._data[\"true_y\"]]\n",
    "        self._false_positives = self._false_predictions.loc[self._false_predictions[\"pred_y\"] > 0.5]\n",
    "        self._false_negatives = self._false_predictions.loc[self._false_predictions[\"pred_y\"] < 0.5]\n",
    "        self._false_positive_files = self._false_positives['# file']\n",
    "        self._false_negative_files = self._false_negatives['# file']\n",
    "        self._false_negatives_sample = np.random.randint(0, len(self._false_negative_files), 2)\n",
    "        self._false_positives_sample = np.random.randint(0, len(self._false_positive_files), 2)\n",
    "        self._false_negative_sample_files = self._false_negative_files.iloc[self._false_negatives_sample]\n",
    "        self._false_positive_sample_files = self._false_positive_files.iloc[self._false_positives_sample]\n",
    "        self._sample_files = self._false_positive_sample_files._append(self._false_negative_sample_files)\n",
    "        self._load_data(sample_files, end=4)\n",
    "    \n",
    "    def _load_data(self, files, start=0, end=10, augment_fn=None):\n",
    "        X = []\n",
    "        y = []\n",
    "        for f in files[start:end]:\n",
    "            print(f'LimeAnalyser._load_data(): Loading file {f}')\n",
    "            img = load_img(f, target_size=(50, 50))\n",
    "            if augment_fn is not None:\n",
    "                sample = augment_fn(img)\n",
    "            else:    \n",
    "                sample = tf.convert_to_tensor(img)\n",
    "            X.append(sample)\n",
    "            y.append(f[-5])\n",
    "        self._x = np.stack(X)\n",
    "        self._y = np.array(y, dtype=float)\n",
    "    \n",
    "    def _setup_explainer(self):\n",
    "        self._model = keras.models.load_model(\"../models/CanDetect.keras\")\n",
    "        self._explainer = lime_image.LimeImageExplainer(verbose=False)\n",
    "        self._segmenter = SegmentationAlgorithm('slic', n_segments=100, compactness=1, sigma=1)\n",
    "\n",
    "analyzer = LimeAnalyser()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: Case_10-04.tif, sample: 106\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "feee81d5915a4648be9b5464de747e8d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=50x50>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAIAAACRXR/mAAAEhElEQVR4Ae1ZS28cRRDuqu6ZDblzggiSKORxCA4E5xAB4oAMJApK4BAkxAEjceAn5MSvgEMQcONxCDZWwiOACBdiEQuCY+HFOIkQ+MDJjr27M93VzTdaezT2rvcxbCIOOytra7qrq775uqq6Zq3U8BoyMGRgyMD/ioGFy3838VS/uNUWmGk7ercHRcLvX/6llAuK2vpqP9pWdVCDc1MLpDWsMfP+sYfamr2nbM1NVMkAUAjig5fAGbi21z2FFVXMvuf2NHHMTS6E0BbScHDIwJCBIQNDBoYM3D0GZj6tbmd8wGfidx/8LN56J0Hz2Pjodl43xmVD2Po9yMbm0ns/6spOHYIPVnldMRS8evq1kaLP6Y9+Vdp4cVAyHD1x9mBxNpcHyVZw4lUiHEVGk1ZPvboJ0E8fzzKxMgYtDRSOvHwoB9EqDBIWBRbn0FCxJuZN+zD9yQ0izUaNnH6kFUTryKbFrdO9j1x+f4aVI6+V5qiiwdixjnx0tjwwtjjSO/R9Klg22pj46Jl9cHzj0iIRa62dRTPqDp/Y2xlNPsu59B8F65wyAXGOuJGwnmJO0CADUlDs2atfJratCFu8D4wtJVl6xZF5/KX9uY9HT+65PvmH1p6M4lhHqlcWBgdLeVY+6JZg1QpZeWhsd461F2FgsCrGYJsYW4mQurhI2EfSKE7Ze0T/rxIDg7UzjsFUpHl2csEwh0AKL4NBIc7wstoLQ0WdFs6Lk93k2c+qgYNPbGBCAUUAaVPhiMmT894TgStU2JETD3eztHW+D1i3v1/imCR14pQXIUUUoSCQh2vnwQ4+B17IYui3r24nDWslPXq6UynfiqVw3+sm3rqypOKImAhBZLzyHhuFuq0qABU7a/c+82Bu1olY5+tJFmfNa/L81VNvHNu46/7dKyz4IAtzGRrNbGLDhnQlO4w5o2qTnYCA8uHJVw5jwefvXlF4Gue7Yylo9FpIDj67a2V5eWX5zsryapLUrUuyMAYa0kIE9go2FYoowqo5AvAxcxzzxfNXizqd5U1P2Vl19MyBXKH67aLsiJFmKN9iEd7rsGam8MtCsIirjZHn3zzeXPX1h9fy5V2FPmAVbQXhtGaJPXIQ9d3ilFFqZqqqgvfCIoxmoqgPmUy0ZaTDbR+ZWLQy/81NMIWfgsQJ2hVviZCUVsCSoIZ6SZGwCHuiNLVaxyj0VtSLrz9WNNJB7hvWzR+W0H6iQiLbVuuAgT4TTrUL4gCFqNZA0+VPjR/p4LXrVN+wYPHP6X+cTWt116jV1tYSr0LWZLFpJLaepqtJevat9Xjq6n47hV4zsbh+1+j9u48/gKDSFKO7Aluo6DZBayNJw91ZWSsql5PLwGp6yhpzjY4B7TGaeOdQwqxFxPNGDpYD1FxVMhOx2CMLA6AhGzXOGYsTCXShgoXyj5o/SXlYOBwtCoMj1AO8GEqCREQnapGgufXSQsknu3ZhvpakLkHVzHYvDt6I10jEIFrUO+culAbUXFgmE69PzFtQFSz+ssgK5FOxiasnSWrtWmLTJMX/AcbfPlka3L9PgypiYQuh1QAAAABJRU5ErkJggg==",
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAyADIDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/ooooAKKKKAHwwy3E8cEEbyyyMESNFLMzE4AAHUk0PDLEkbyRuiyrvjLKQHXJXI9RkEfUH0rW8P67H4fuftqaXaXl9HIj28t0XZYcBs4RSASSVIJ6beBnkP8W+JJfFfiKfVZI3hV1RI4WlMgiVVAwDgcE5boOWNPSw9LGHRRRSEFFFFABVv+y9Q/s/8AtD7DdfYv+fjyW8vrt+9jHXj61Ur3Lxlq9h4b0Cw8NwapcWlzItvGLhd/mW9uGwZcqBuPyEFQQTmrjFNNspK54bU1zazWcqxTpsdo0lAyD8rqHU8eqsD+Nel69bz/AAz0yKDRNZ0eS/M2y5kS2UXoVl3AMGZ/kwB2XkL1yTXml1d3N9cPcXdxLcTvjdJK5dmwMDJPPQAUmraCasQ0UUVIgroPBul6JrHiBLXX9UOnWRjZvMBC72HRdzfKvc5PpjqRXP0U0CPojRPhF4InsmvIJptVt5f9XK91lRgkHaYtoPPBznp25rM0z4h3k3h3xB4kl0KO0hgihSyfy2YzEl1wznaHVXP8ONoY9TWx8Ntcg1HwRH9i09NOhtJmtzCkzSKzYV2YFuQCzngk49TXMfFLxFdaRYafpmnx2sdpNuDRtbo67U27VCsCoAznp2GMV0WtHmRteyujgPG8F7Lqw1e91Cxv5L/cXlsXDRI6YHljBz8qGPqM/N35J5irt9q13qEMMM/kLFCzMiQ28cIBbAY4RRknavX0qlXO2m9DJhRRRSEFFFFAH074Vhjh8GaIkUaIhsIXKqoALMgLH6kkk+pNcn8S4o38JXrNGpZDGyEjlTvUZHpwSPxNFFdn/Lv5HQ/gPDqKKK4znCiiigD/2Q=="
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.explain_tagged_files(3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T01:49:50.010763215Z",
     "start_time": "2024-01-23T01:49:44.195436672Z"
    }
   },
   "id": "71fe4917819156b7",
   "execution_count": 202
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
